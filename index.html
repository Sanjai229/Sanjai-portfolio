<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Sanjai | Data Science Portfolio</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Google Font -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <style>
        body {
            font-family: 'Inter', sans-serif;
            max-width: 880px;
            margin: auto;
            padding: 40px 20px;
            line-height: 1.7;
            color: #1f2937;
            background-color: #ffffff;
        }

        h1 {
            font-size: 36px;
            margin-bottom: 6px;
        }

        h2 {
            font-size: 22px;
            margin-top: 50px;
            margin-bottom: 15px;
            padding-bottom: 6px;
            border-bottom: 2px solid #e5e7eb;
        }

        p {
            font-size: 16px;
            margin: 10px 0;
        }

        a {
            color: #2563eb;
            text-decoration: none;
            font-weight: 500;
        }

        a:hover {
            text-decoration: underline;
        }

        .subtitle {
            font-size: 16px;
            color: #6b7280;
            margin-bottom: 25px;
        }

        .project-box {
            background: #f9fafb;
            padding: 20px;
            border-radius: 10px;
            margin-top: 15px;
        }

        .tags {
            margin-top: 10px;
        }

        .tag {
            display: inline-block;
            background: #e5e7eb;
            padding: 6px 12px;
            margin: 6px 6px 0 0;
            border-radius: 999px;
            font-size: 13px;
            color: #374151;
        }
    </style>
</head>


<body>

<h1>Sanjai</h1>
<p class="subtitle">
Master’s student in Data Science at the University of Adelaide.<br>
Focused on building end-to-end machine learning systems with real audio data
and understanding their limitations in production-like settings.
</p>

    
<h2>About</h2>
<p>
I build end-to-end machine learning systems with a focus on speech processing,
data pipelines, and real-world deployment constraints.
</p>


<h2>Projects</h2>

<div class="project-box">

    <p><strong>Real-Time Speech Transcription & Gender Detection System</strong></p>

    <p>
        <strong>Problem & Motivation</strong><br>
        Most speech-based applications demonstrate transcription using pre-recorded
        datasets, without addressing real-time microphone input or downstream audio
        analytics. I wanted to build an end-to-end system that captures live speech
        from a browser, performs transcription, and extracts speaker-level insights
        under real-world constraints such as inconsistent audio formats and noise.
    </p>

    <p>
        <strong>System Design</strong><br>
        The system uses a browser-based audio recorder to capture speech and send it
        as a POST request to a Flask backend. The backend standardises the audio into
        WAV format, performs speech-to-text transcription using Whisper, extracts MFCC
        features from the same audio, and predicts speaker gender using a trained
        Random Forest model. Results are returned as JSON and rendered dynamically
        on the frontend.
    </p>

    <p>
        <strong>Key Challenges</strong><br>
        – Converting browser-recorded audio into a consistent WAV format for ML models<br>
        – Ensuring feature consistency between MFCC extraction during training and inference<br>
        – Debugging end-to-end failures across frontend, backend, and model layers
    </p>

    <p>
        <strong>Trade-offs & Learnings</strong><br>
        I prioritised robustness and system clarity over aggressive optimisation.
        This project strengthened my understanding of audio preprocessing pipelines,
        model integration in production-style systems, and how ML performance depends
        heavily on data handling rather than model choice alone.
    </p>

    <div class="tags">
        <span class="tag">Python</span>
        <span class="tag">Flask</span>
        <span class="tag">Whisper</span>
        <span class="tag">Audio Processing</span>
        <span class="tag">Machine Learning Systems</span>
    </div>

    <p style="margin-top: 12px;">
        <a href="https://github.com/Sanjai229/Speech-recognition">
            View GitHub Repository →
        </a>
        &nbsp;|&nbsp;
        <a href="https://medium.com/@sanjaicena123/real-time-speech-transcription-and-gender-detection-web-application-c04429134c37">
            Read Technical Blog →
        </a>
    </p>

</div>


<h2>Blogs</h2>

<ul>
    <li>
        <a href="https://medium.com/@sanjaicena123/real-time-speech-transcription-and-gender-detection-web-application-c04429134c37">
        Speech Recognition and Gender Detection System
        </a>

    </li>
</ul>



<h2>Connect</h2>
<ul>
    <li><a href="https://github.com/Sanjai229">GitHub</a></li>
    <li><a href="https://www.linkedin.com/in/sanjaiarul/">LinkedIn</a></li>
</ul>

</body>
</html>
